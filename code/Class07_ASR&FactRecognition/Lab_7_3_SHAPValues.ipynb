{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Lab 7.3 — SHAP Values (Explainable AI for Digital Health)\n\nIn this lab, you will train a simple **heart disease risk** classifier and use **SHAP** to explain:\n- **Global** behavior (which features matter most overall)\n- **Local** behavior (why a specific case gets a high/low risk prediction)\n\nDataset: `heart_disease_uci.csv`\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Learning objectives\nBy the end of this lab, you should be able to:\n1. Load and preprocess a clinical dataset (mixed numeric + categorical)\n2. Train and evaluate a baseline classification model\n3. Use **SHAP** to explain predictions:\n   - Global: *summary plot*, *feature importance bar plot*\n   - Local: *waterfall plot* for individual cases\n4. Communicate model explanations in plain language (not causality)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# If you run this in Google Colab, install dependencies first\n!pip -q install shap scikit-learn pandas matplotlib\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    roc_auc_score,\n    accuracy_score,\n)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport shap\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Load data\n\nIf you are using **Colab**, upload `heart_disease_uci.csv` to `/content/`.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def resolve_data_path(filename: str) -> str:\n    candidates = [\n        filename,\n        os.path.join(\".\", filename),\n        os.path.join(\"/content\", filename),  # Colab default\n    ]\n    for p in candidates:\n        if os.path.exists(p):\n            return p\n    raise FileNotFoundError(\n        f\"Could not find {filename}. If you are on Colab, click the folder icon and upload it to /content.\"\n    )\n\ndata_path = resolve_data_path(\"heart_disease_uci.csv\")\ndf = pd.read_csv(data_path)\n\nprint(\"Loaded:\", data_path)\nprint(\"Shape:\", df.shape)\ndf.head()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Define the prediction target\n\nIn this dataset, `num` is commonly used as **disease severity**:\n- `num = 0` means *no heart disease*\n- `num > 0` means *heart disease present*\n\nFor this lab, we create a **binary** target:  \n`target = 1 if num > 0 else 0`\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Basic checks\nprint(df[\"num\"].value_counts(dropna=False).sort_index())\n\n# Binary target\ndf[\"target\"] = (df[\"num\"] > 0).astype(int)\n\nprint(\"\\nBinary target distribution:\")\nprint(df[\"target\"].value_counts(normalize=True).rename(\"proportion\"))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Prepare features (X) and labels (y)\n\nWe drop:\n- `id` (identifier)\n- `num` (original multi-class / severity label)\n\nEverything else becomes an input feature.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "drop_cols = [\"id\", \"num\"]\nX = df.drop(columns=drop_cols + [\"target\"], errors=\"ignore\")\ny = df[\"target\"].astype(int)\n\n# Identify feature types\ncat_cols = X.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\nnum_cols = [c for c in X.columns if c not in cat_cols]\n\nprint(\"Numeric columns:\", num_cols)\nprint(\"Categorical/boolean columns:\", cat_cols)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Train/test split\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "X_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.25,\n    random_state=42,\n    stratify=y\n)\n\nprint(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Build a baseline model (preprocessing + classifier)\n\nWe will use:\n- **Imputation** (fill missing values)\n- **One-hot encoding** for categorical features\n- **RandomForestClassifier** as a strong, simple baseline\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "numeric_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n])\n\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n])\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, num_cols),\n        (\"cat\", categorical_transformer, cat_cols),\n    ],\n    remainder=\"drop\",\n)\n\nmodel = RandomForestClassifier(\n    n_estimators=400,\n    random_state=42,\n    class_weight=\"balanced\",\n    n_jobs=-1,\n)\n\nclf = Pipeline(steps=[\n    (\"preprocess\", preprocess),\n    (\"model\", model),\n])\n\nclf\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Train + evaluate\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "clf.fit(X_train, y_train)\n\n# Predictions\ny_pred = clf.predict(X_test)\ny_prob = clf.predict_proba(X_test)[:, 1]\n\nacc = accuracy_score(y_test, y_pred)\nauc = roc_auc_score(y_test, y_prob)\n\nprint(f\"Accuracy: {acc:.3f}\")\nprint(f\"ROC-AUC : {auc:.3f}\\n\")\n\nprint(\"Classification report:\")\nprint(classification_report(y_test, y_pred))\n\nprint(\"Confusion matrix:\")\nconfusion_matrix(y_test, y_pred)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7) SHAP explanations\n\n### Important concept\nSHAP explains **the model's behavior** (how it uses inputs), not medical causality.\n\nBecause our model uses one-hot encoding, we compute SHAP on the **transformed feature matrix**.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Transform data into the model's feature space\nX_train_t = clf.named_steps[\"preprocess\"].transform(X_train)\nX_test_t  = clf.named_steps[\"preprocess\"].transform(X_test)\n\n# Convert sparse → dense (SHAP plots are easiest with dense arrays)\ndef to_dense(X):\n    return X.toarray() if hasattr(X, \"toarray\") else np.asarray(X)\n\nX_train_dense = to_dense(X_train_t)\nX_test_dense  = to_dense(X_test_t)\n\n# Build feature names (numeric + one-hot categorical)\nohe = clf.named_steps[\"preprocess\"].named_transformers_[\"cat\"].named_steps[\"onehot\"]\ncat_feature_names = ohe.get_feature_names_out(cat_cols).tolist()\nfeature_names = num_cols + cat_feature_names\n\nlen(feature_names), X_test_dense.shape\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 7.1 Global explanation — SHAP summary plot\n- Shows which features matter most overall\n- Color indicates feature value (low → high)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# TreeExplainer works well for tree-based models (like RandomForest)\nexplainer = shap.TreeExplainer(clf.named_steps[\"model\"])\n\n# For binary classification, SHAP can return:\n# - a list of arrays (one per class), or\n# - a single array, depending on SHAP/model version.\nshap_values = explainer.shap_values(X_test_dense)\n\n# Pick SHAP values for the positive class (heart disease present)\nif isinstance(shap_values, list) and len(shap_values) == 2:\n    shap_pos = shap_values[1]\nelse:\n    shap_pos = shap_values\n\n# Summary plot (beeswarm)\nshap.summary_plot(shap_pos, X_test_dense, feature_names=feature_names, show=True)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 7.2 Global explanation — feature importance (bar)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "shap.summary_plot(shap_pos, X_test_dense, feature_names=feature_names, plot_type=\"bar\", show=True)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 7.3 Dependence plot — how one feature affects prediction\n\nPick one feature (often a top feature from the bar plot) and visualize its effect.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Choose a feature to inspect (edit this if you want)\nfeature_to_plot = feature_names[0]  # change to a more interesting feature after you see the bar plot\nprint(\"Feature:\", feature_to_plot)\n\nshap.dependence_plot(\n    feature_to_plot,\n    shap_pos,\n    X_test_dense,\n    feature_names=feature_names,\n    show=True\n)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8) Local explanation — why this case got this prediction\n\nWe will explain two cases:\n- A **high-risk** case (highest predicted probability)\n- A **low-risk** case (lowest predicted probability)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Get predicted probabilities for each test case\ntest_probs = clf.predict_proba(X_test)[:, 1]\n\nhigh_idx = int(np.argmax(test_probs))\nlow_idx  = int(np.argmin(test_probs))\n\nprint(\"High-risk predicted probability:\", test_probs[high_idx])\nprint(\"Low-risk predicted probability :\", test_probs[low_idx])\n\n# Show original (human-readable) input rows\ndisplay(pd.DataFrame({\n    \"case\": [\"HIGH risk\", \"LOW risk\"],\n    \"predicted_prob\": [test_probs[high_idx], test_probs[low_idx]],\n}))\nprint(\"\\nHIGH-risk case inputs:\")\ndisplay(X_test.iloc[high_idx:high_idx+1])\nprint(\"\\nLOW-risk case inputs:\")\ndisplay(X_test.iloc[low_idx:low_idx+1])\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Waterfall plots (local explanations)\n# SHAP \"expected_value\" is the baseline model output; feature contributions push it up/down.\n\n# Create Explanation objects\nbase = explainer.expected_value\n# expected_value can also be a list for binary classifiers\nif isinstance(base, (list, np.ndarray)) and len(np.atleast_1d(base)) == 2:\n    base_pos = base[1]\nelse:\n    base_pos = float(np.atleast_1d(base)[0])\n\n# High-risk case\nexp_high = shap.Explanation(\n    values=shap_pos[high_idx],\n    base_values=base_pos,\n    data=X_test_dense[high_idx],\n    feature_names=feature_names\n)\n\n# Low-risk case\nexp_low = shap.Explanation(\n    values=shap_pos[low_idx],\n    base_values=base_pos,\n    data=X_test_dense[low_idx],\n    feature_names=feature_names\n)\n\nprint(\"Waterfall — HIGH risk\")\nshap.plots.waterfall(exp_high, max_display=12)\n\nprint(\"\\nWaterfall — LOW risk\")\nshap.plots.waterfall(exp_low, max_display=12)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 9) Student tasks (submit screenshots + short answers)\n\n1. **Global:** Take a screenshot of the **bar plot** and write 2–3 sentences:\n   - Top 3 features and what direction they influence risk (based on the summary plot).\n\n2. **Local:** Take screenshots of both **waterfall plots** and write:\n   - Which 2 features push risk up the most for the high-risk case?\n   - Which 2 features push risk down the most for the low-risk case?\n\n3. **Dependence:** Create one dependence plot for a top feature and explain what you observe.\n\n### Reminder\nSHAP explains what the **model** learned from this dataset. It does **not** prove medical causality.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}